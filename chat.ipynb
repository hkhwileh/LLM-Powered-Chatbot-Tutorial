{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this tutorial We'll go over an example of how to design and implement an LLM-powered chatbot. \n",
    "\n",
    "This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Make sure you have groq API key from https://groq.com/\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AIMessage(content=\"You're right! As a large language model, I don't have memory of past conversations.  \\n\\nSo, it's nice to meet you, Hassan Khwileh. How can I help you today? ðŸ˜Š \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 60, 'total_tokens': 112, 'completion_time': 0.094545455, 'prompt_time': 0.001625224, 'queue_time': 0.020201761999999998, 'total_time': 0.096170679}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-140d1b44-a92c-4539-96b5-6993f1f02072-0', usage_metadata={'input_tokens': 60, 'output_tokens': 52, 'total_tokens': 112}),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
    "response=model.invoke([HumanMessage(content=\"Hello , My Name is Hassan Khwileh, how you can help me todya ?\"),\n",
    "                       AIMessage(content=\"Hello Hassan, its nice to meet you, as Lead Data Scientist, \"),\n",
    "                       HumanMessage(content=\"Hey do you remember my name ?\"),]),\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and no way to know your name or what you do.\\n\\nCan you tell me your name? ðŸ˜Š  I'd love to know!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 21, 'total_tokens': 64, 'completion_time': 0.078181818, 'prompt_time': 0.00014032, 'queue_time': 0.018917237, 'total_time': 0.078322138}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-386b7a5b-5a21-4acd-be37-0fb50933758b-0', usage_metadata={'input_tokens': 21, 'output_tokens': 43, 'total_tokens': 64})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        #HumanMessage(content=\"Hi , My name is Hassan and I am a Lead AI Engineer\"),\n",
    "        #AIMessage(content=\"Hello Hassan Khwileh! It's nice to meet you. \\n\\nAs a Lead AI Engineer, what kind of projects are you working on these days? \\n\\nI'm always eager to learn more about the exciting work being done in the field of AI.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Dictionary to store chat session histories.\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"\n",
    "    Retrieve or create a chat message history for a given session ID.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): The unique identifier for the chat session.\n",
    "\n",
    "    Returns:\n",
    "        BaseChatMessageHistory: The chat message history object associated with the session ID.\n",
    "\n",
    "    Notes:\n",
    "        If a session history does not exist for the provided session ID, \n",
    "        a new `ChatMessageHistory` instance is created and stored.\n",
    "    \"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
